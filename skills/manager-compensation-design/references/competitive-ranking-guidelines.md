# Competitive Ranking Guidelines

## The Reality of Merit Systems

**Fundamental Truth:** In any merit-based system, if someone is first, someone else must be last.

This is not mean—it's mathematical. Just like sports:
- Not every team can win the championship
- Not every player can be MVP
- Not every employee can be "above average"

## Ranking Distribution Options

### Option 1: Normal Distribution (Bell Curve)

```
Top 10%     | Outstanding
Next 20%    | Exceeds Expectations
Middle 40%  | Meets Expectations
Next 20%    | Needs Improvement
Bottom 10%  | Unsatisfactory
```

**Pros:**
- Statistically sound
- Forces differentiation
- Aligns with many corporate practices

**Cons:**
- Can feel arbitrary
- May not reflect actual talent distribution
- Can create unhealthy competition

### Option 2: Flexible Distribution

```
Top 15-20%  | Outstanding
Next 25-30% | Exceeds Expectations
Middle 30-40%| Meets Expectations
Next 15-20% | Needs Improvement
Bottom 5-10% | Unsatisfactory
```

**Pros:**
- More adaptable to team quality
- Allows for strong teams
- Less rigid

**Cons:**
- Requires manager judgment
- Can lead to grade inflation

### Option 3: No Forced Distribution

```
No set percentages
Rank based on actual performance
All could be "above average" in a strong team
All could be "below average" in a weak team
```

**Pros:**
- Most accurate to reality
- Fair to strong teams
- Flexible

**Cons:**
- Budget unpredictability
- May not differentiate enough
- Requires strong calibration

## Ranking Criteria Development

### For Individual Performance

1. **Results Achievement** (40%)
   - Did they meet/exceed objectives?
   - Quality of deliverables
   - Impact on business metrics

2. **Skill & Competency** (30%)
   - Technical skills
   - Leadership capabilities
   - Problem-solving ability

3. **Behavior & Culture** (30%)
   - Team collaboration
   - Innovation
   - Customer focus
   - Values alignment

## Calibration Process

1. **Individual Rankings:** Manager ranks their direct reports
2. **Peer Calibration:** Managers meet to compare rankings across teams
3. **Leadership Review:** Senior leadership reviews for consistency
4. **Final Approval:** HR and executive sign-off

## Common Pitfalls

### ❌ The "Lake Wobegon" Effect
- "All children are above average"
- Everyone gets top ratings
- Destroys credibility of the system

### ❌ Recency Bias
- Judging based only on recent performance
- Forgetting earlier achievements or failures

### ❌ Halo Effect
- One great trait overshadows everything else
- Or one bad trait ruins the entire rating

### ❌ Central Tendency
- Everyone gets "average" ratings
- Manager avoids difficult conversations
- No differentiation

### ❌ Leniency/Severity Errors
- Consistently rating too high or too low
- Personal bias affecting rankings

## Best Practices

1. **Document Everything:** Keep specific examples for each rating
2. **Calibrate Regularly:** Compare across teams to ensure fairness
3. **Communicate Clearly:** Explain the ranking process upfront
4. **Focus on Development:** Use rankings to guide growth, not just compensation
5. **Review Annually:** Ensure the system is working as intended